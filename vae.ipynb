{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be21cde",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9147d9-2432-43eb-a291-2d03e8da4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import haiku as hk\n",
    "import optax\n",
    "import chex\n",
    "from tqdm import tqdm\n",
    "from utils import BatchManager, load_dataset, save_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbfd5e-de4a-4eea-9110-ef0cc0d0c80e",
   "metadata": {},
   "source": [
    "## Configuration and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for each dataset\n",
    "dataset_name = 'checkerboard'\n",
    "dataset_configs = {\n",
    "    'checkerboard': {\n",
    "        'epochs': 500\n",
    "    },\n",
    "    'gaussian_mixture': {\n",
    "        'epochs': 500\n",
    "    },\n",
    "    'pinwheel': {\n",
    "        'epochs': 500\n",
    "    },\n",
    "    'spiral': {\n",
    "        'epochs': 500\n",
    "    }\n",
    "}\n",
    "\n",
    "config = dataset_configs[dataset_name]\n",
    "config['batch_size'] = 128\n",
    "config['learning_rate'] = 1e-3\n",
    "config['beta'] = 0.002\n",
    "config['enc_layer_dim'] = [128, 64]\n",
    "config['dec_layer_dim'] = [64, 128]\n",
    "config['latent_dim'] = 20\n",
    "config['output_dim'] = 2\n",
    "X_train, X_test = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc63e9-9a59-4f79-8f55-0b4465ed1ff2",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c901fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    layer_dim: Sequence[int]\n",
    "    latent_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        for f in self.layer_dim:\n",
    "            x = nn.Dense(f)(x)\n",
    "            x = nn.swish(x)\n",
    "        x = nn.Dense(self.latent_dim * 2)(x)\n",
    "        mean = x[..., :self.latent_dim]\n",
    "        log_var = x[..., self.latent_dim:]\n",
    "        return mean, log_var\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    layer_dim: Sequence[int]\n",
    "    output_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, z: jax.Array) -> jax.Array:\n",
    "        for f in self.layer_dim:\n",
    "            z = nn.Dense(f)(z)\n",
    "            z = nn.swish(z)\n",
    "        x_recon = nn.Dense(self.output_dim)(z)\n",
    "        return x_recon\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    enc_layer_dim: Sequence[int]\n",
    "    dec_layer_dim: Sequence[int]\n",
    "    latent_dim: int\n",
    "    output_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.encoder = Encoder(self.enc_layer_dim, self.latent_dim)\n",
    "        self.decoder = Decoder(self.dec_layer_dim, self.output_dim)\n",
    "\n",
    "    def __call__(self, x: jax.numpy.ndarray, key: chex.PRNGKey):\n",
    "        mean, log_var = self.encoder(x)\n",
    "        z = mean + jnp.exp(0.5 * log_var) * jax.random.normal(key, mean.shape)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mean, log_var\n",
    "    \n",
    "model = VAE(\n",
    "    enc_layer_dim=config['enc_layer_dim'],\n",
    "    dec_layer_dim=config['dec_layer_dim'],\n",
    "    latent_dim=config['latent_dim'],\n",
    "    output_dim=config['output_dim']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6f3f6-6de7-4543-8979-b8f124f9dba7",
   "metadata": {},
   "source": [
    "## Training Preparation\n",
    "Set up the optimizer, loss functions, and other training utilities.## Define the VAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24325f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adam(learning_rate=config['learning_rate'])\n",
    "prng_seq = hk.PRNGSequence(jax.random.PRNGKey(0))\n",
    "\n",
    "def vae_loss(params: chex.ArrayTree, batch: jax.Array, key: chex.PRNGKey):\n",
    "    batch_recon, mean, log_var = model.apply(params, batch, key)\n",
    "    recon_loss = jnp.mean(jnp.square(batch - batch_recon))  # Reconstruction loss\n",
    "    kl_div = - jnp.mean( jnp.sum(1 + log_var - jnp.square(mean) - jnp.exp(log_var), axis=1))  # KL divergence\n",
    "    return recon_loss + config['beta'] * kl_div\n",
    "\n",
    "@jax.jit\n",
    "def do_batch_update(batch: jax.Array, params: chex.ArrayTree, opt_state: optax.OptState, key: chex.PRNGKey) -> tuple[float, chex.ArrayTree, optax.OptState]:\n",
    "    loss, grad = jax.value_and_grad(vae_loss)(params, batch, key)\n",
    "    updates, opt_state = optimizer.update(grad, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return loss, params, opt_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80891322-1050-4d88-8535-537af639b635",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db572121",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.init(next(prng_seq), X_train, next(prng_seq))\n",
    "opt_state = optimizer.init(params)\n",
    "bm = BatchManager(X_train, config['batch_size'], key=next(prng_seq))\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1027f-875e-4e28-9f20-7eed921ad9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(config['epochs']), \"Epoch\"):\n",
    "    batch_loss = 0\n",
    "    for _ in range(bm.num_batches):\n",
    "        batch = next(bm)\n",
    "        train_loss, params, opt_state = do_batch_update(batch, params, opt_state, key=next(prng_seq))\n",
    "        batch_loss += train_loss\n",
    "    test_loss = vae_loss(params, X_test, next(prng_seq))\n",
    "    train_losses.append(batch_loss / bm.num_batches)\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830061ed",
   "metadata": {},
   "source": [
    "## Training Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply moving average filer to losses\n",
    "window_size = 100\n",
    "window = np.ones(window_size) / window_size\n",
    "train_losses_f = np.convolve(train_losses, window, mode='valid')\n",
    "test_losses_f = np.convolve(test_losses, window, mode='valid')\n",
    "x_pos = np.arange(window_size // 2, window_size // 2 + train_losses_f.shape[0])\n",
    "\n",
    "plt.plot(train_losses, label='Train Losses')\n",
    "plt.plot(test_losses, label='Test Losses')\n",
    "plt.plot(x_pos, train_losses_f, label='Smoothed Train Losses')\n",
    "plt.plot(x_pos, test_losses_f, label='Smoothed Test Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('VAE Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcfe699-3cfa-431a-9d7c-a03362201af5",
   "metadata": {},
   "source": [
    "## Sample Generation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(params: chex.ArrayTree, key: chex.PRNGKey, num_samples: int):\n",
    "    x, _, _ = model.apply(params, X_train, key)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c06451-8ac8-4fbf-ad03-6d361d1054f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample_model(params, next(prng_seq), 2000)\n",
    "\n",
    "plt.scatter(samples[:, 0], samples[:, 1], marker='.', label='Sampled')\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], alpha=0.2, marker='o', label='Train')\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], alpha=0.2, marker='o', label='Test')\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.axis('equal')\n",
    "plt.xlim([-4, 4])\n",
    "plt.ylim([-4, 4])\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeaa54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model outputs\n",
    "save_samples('vae', dataset_name, samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
