{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b3aea2",
   "metadata": {},
   "source": [
    "# Energy Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9147d9-2432-43eb-a291-2d03e8da4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import haiku as hk\n",
    "import optax\n",
    "import chex\n",
    "from tqdm import tqdm\n",
    "from utils import BatchManager, load_dataset, save_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbfd5e-de4a-4eea-9110-ef0cc0d0c80e",
   "metadata": {},
   "source": [
    "## Configuration and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for each dataset\n",
    "dataset_name = 'checkerboard'\n",
    "dataset_configs = {\n",
    "    'checkerboard': {\n",
    "        'epochs': 200\n",
    "    },\n",
    "    'gaussian_mixture': {\n",
    "        'epochs': 200\n",
    "    },\n",
    "    'pinwheel': {\n",
    "        'epochs': 200\n",
    "    },\n",
    "    'spiral': {\n",
    "        'epochs': 200\n",
    "    }\n",
    "}\n",
    "\n",
    "config = dataset_configs[dataset_name]\n",
    "config['batch_size'] = 128\n",
    "config['learning_rate'] = 1e-3\n",
    "config['mlp_layer_dim'] = [64, 64, 1]\n",
    "X_train, X_test = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc63e9-9a59-4f79-8f55-0b4465ed1ff2",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5275295-390b-4545-b8f4-222e473b3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    layer_dim: Sequence[int]\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        for f in self.layer_dim[:-1]:\n",
    "            x = nn.Dense(f)(x)\n",
    "            x = nn.swish(x)\n",
    "        x = nn.Dense(self.layer_dim[-1])(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "model = MLP(layer_dim=config['mlp_layer_dim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6f3f6-6de7-4543-8979-b8f124f9dba7",
   "metadata": {},
   "source": [
    "## Training Preparation\n",
    "Set up the optimizer, loss functions, and other training utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56523620",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adam(learning_rate=config['learning_rate'])\n",
    "prng_seq = hk.PRNGSequence(jax.random.PRNGKey(0))\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=(\"num_steps\",))\n",
    "def langevin_sampling(\n",
    "    params: chex.ArrayTree,\n",
    "    key: chex.PRNGKey,\n",
    "    step_size: float,\n",
    "    initial_samples: jax.Array,\n",
    "    num_steps: int,\n",
    ") -> jax.Array:\n",
    "\n",
    "    def scan_fn(carry, _):\n",
    "        states, key = carry\n",
    "        key, sk = jax.random.split(key)\n",
    "        noise = jax.random.normal(sk, shape=states.shape)\n",
    "        score = jax.vmap(jax.grad(lambda x: model.apply(params, x)))(states)\n",
    "        next_states = states + step_size * score + jnp.sqrt(2 * step_size) * noise\n",
    "        return (next_states, key), None\n",
    "\n",
    "    states = initial_samples\n",
    "    (states, _), _ = jax.lax.scan(scan_fn, (states, key), jnp.arange(num_steps))\n",
    "    return states\n",
    "\n",
    "def ce_loss_grad(params: chex.ArrayTree, batch: jax.Array, key: chex.PRNGKey) -> float:\n",
    "    # Sample from model\n",
    "    key1, key2 = jax.random.split(key)\n",
    "    batch_model = langevin_sampling(params, key1, 5e-3, 2 * jax.random.normal(key2, shape=batch.shape), 1000)\n",
    "\n",
    "    # Apply model and compute gradient for each sample\n",
    "    f = lambda params, x: model.apply(params, x)\n",
    "    df_data = jax.vmap(jax.grad(f), in_axes=(None, 0))(params, batch)\n",
    "    df_model = jax.vmap(jax.grad(f), in_axes=(None, 0))(params, batch_model)\n",
    "    grad = jax.tree.map(jnp.subtract, df_model, df_data)  # -(df_data - df_model)\n",
    "\n",
    "    # Sum gradients across samples\n",
    "    grad = jax.tree.map(lambda x: jnp.sum(x, axis=0), grad)\n",
    "\n",
    "    return grad\n",
    "\n",
    "@jax.jit\n",
    "def do_batch_update(batch: jax.Array, params: chex.ArrayTree, opt_state: optax.OptState, key: chex.PRNGKey) -> tuple[float, chex.ArrayTree, optax.OptState]:\n",
    "    grad = ce_loss_grad(params, batch, key)\n",
    "    updates, opt_state = optimizer.update(grad, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80891322-1050-4d88-8535-537af639b635",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95374b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.init(next(prng_seq), X_train[:1, ...])\n",
    "opt_state = optimizer.init(params)\n",
    "bm = BatchManager(X_train, config['batch_size'], key=next(prng_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1027f-875e-4e28-9f20-7eed921ad9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_energies = []\n",
    "test_energies = []\n",
    "for epoch in tqdm(range(config['epochs']), \"Epoch\"):\n",
    "    for _ in range(bm.num_batches):\n",
    "        batch = next(bm)\n",
    "        params, opt_state = do_batch_update(batch, params, opt_state, key=next(prng_seq))\n",
    "    train_energy = jnp.mean(model.apply(params, X_train))\n",
    "    test_energy = jnp.mean(model.apply(params, X_test))\n",
    "    train_energies.append(train_energy)\n",
    "    test_energies.append(test_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e313ffd2",
   "metadata": {},
   "source": [
    "## Training Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply moving average filer to losses\n",
    "window_size = 10\n",
    "window = np.ones(window_size) / window_size\n",
    "train_losses_f = np.convolve(train_energies, window, mode='valid')\n",
    "test_losses_f = np.convolve(test_energies, window, mode='valid')\n",
    "x_pos = np.arange(window_size // 2, window_size // 2 + train_losses_f.shape[0])\n",
    "\n",
    "# Plot losses\n",
    "plt.plot(train_energies, label='Train Energy')\n",
    "plt.plot(test_energies, label='Test Energy')\n",
    "plt.plot(x_pos, train_losses_f, label='Smoothed Train Energies')\n",
    "plt.plot(x_pos, test_losses_f, label='Smoothed Test Energies')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Energy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcfe699-3cfa-431a-9d7c-a03362201af5",
   "metadata": {},
   "source": [
    "## Sample Generation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c06451-8ac8-4fbf-ad03-6d361d1054f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = langevin_sampling(params, next(prng_seq), 5e-3, 2 * jax.random.normal(next(prng_seq), shape=(2000, 2)), 1000)\n",
    "\n",
    "plt.scatter(samples[:, 0], samples[:, 1], marker='.', label='Sampled')\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], alpha=0.2, marker='o', label='Train')\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], alpha=0.2, marker='o', label='Test')\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.axis('equal')\n",
    "plt.xlim([-4, 4])\n",
    "plt.ylim([-4, 4])\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfda21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model outputs\n",
    "save_samples('ebm', dataset_name, samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
