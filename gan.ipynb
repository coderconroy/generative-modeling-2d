{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bd07ea",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9147d9-2432-43eb-a291-2d03e8da4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import haiku as hk\n",
    "import optax\n",
    "import chex\n",
    "from tqdm import tqdm\n",
    "from utils import BatchManager, load_dataset, save_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbfd5e-de4a-4eea-9110-ef0cc0d0c80e",
   "metadata": {},
   "source": [
    "## Configuration and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for each dataset\n",
    "dataset_name = 'checkerboard'\n",
    "dataset_configs = {\n",
    "    'checkerboard': {\n",
    "        'epochs': 1000\n",
    "    },\n",
    "    'gaussian_mixture': {\n",
    "        'epochs': 1000\n",
    "    },\n",
    "    'pinwheel': {\n",
    "        'epochs': 1000\n",
    "    },\n",
    "    'spiral': {\n",
    "        'epochs': 1000\n",
    "    }\n",
    "}\n",
    "\n",
    "config = dataset_configs[dataset_name]\n",
    "config['batch_size'] = 128\n",
    "config['d_learning_rate'] = 1e-3\n",
    "config['g_learning_rate'] = 1e-3\n",
    "config['d_layer_dim'] = [30, 20, 10, 1]\n",
    "config['g_layer_dim'] = [16, 8, 4, 2]\n",
    "config['latent_dim'] = 10\n",
    "config['k'] = 1  # Discriminator training iterations\n",
    "X_train, X_test = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc63e9-9a59-4f79-8f55-0b4465ed1ff2",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    layer_dim: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jax.Array, train: bool) -> jax.Array:\n",
    "        for f in self.layer_dim[:-1]:\n",
    "            x = nn.Dense(f)(x)\n",
    "            x = nn.relu(x)\n",
    "            x = nn.Dropout(rate=0.1, deterministic=not train)(x)\n",
    "        x = nn.Dense(self.layer_dim[-1])(x)\n",
    "        x = nn.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "discriminator = Discriminator(layer_dim=config['d_layer_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    layer_dim: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, z: jax.Array) -> jax.Array:\n",
    "        for f in self.layer_dim[:-1]:\n",
    "            z = nn.Dense(f)(z)\n",
    "            z = nn.relu(z)\n",
    "        x = nn.Dense(self.layer_dim[-1])(z)\n",
    "        return x\n",
    "    \n",
    "generator = Generator(layer_dim=config['g_layer_dim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6f3f6-6de7-4543-8979-b8f124f9dba7",
   "metadata": {},
   "source": [
    "## Training Preparation\n",
    "Set up the optimizer, loss functions, and other training utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = optax.adam(learning_rate=config['d_learning_rate'])\n",
    "g_optimizer = optax.adam(learning_rate=config['g_learning_rate'])\n",
    "prng_seq = hk.PRNGSequence(jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=['train'])\n",
    "def gan_loss(d_params:chex.ArrayTree, g_params:chex.ArrayTree, batch: jax.Array, key: chex.PRNGKey, train: bool):\n",
    "    # Generate sample\n",
    "    key, z_key = jax.random.split(key)\n",
    "    z_batch = jax.random.normal(z_key, (batch.shape[0], config['latent_dim']))\n",
    "    fake_batch = generator.apply(g_params, z_batch)\n",
    "\n",
    "    # Apply discriminator\n",
    "    key1, key2 = jax.random.split(key)\n",
    "    real_preds = discriminator.apply(d_params, batch, train=train, rngs={'dropout': key1})\n",
    "    fake_preds = discriminator.apply(d_params, fake_batch, train=train, rngs={'dropout': key2})\n",
    "\n",
    "    # Compute loss\n",
    "    d_loss = -jnp.mean(jnp.log(real_preds) + jnp.log(1 - fake_preds))\n",
    "    g_loss = -jnp.mean(jnp.log(fake_preds))\n",
    "    # g_loss = jnp.mean(jnp.log(1 - fake_preds))\n",
    "\n",
    "    return d_loss, g_loss\n",
    "\n",
    "@jax.jit\n",
    "def do_batch_update(batch, d_params, g_params, opt_d_state, opt_g_state, key):\n",
    "    # Train discriminator\n",
    "    for _ in range(config['k']):\n",
    "        key, z_key = jax.random.split(key)\n",
    "        compute_d_loss = lambda d_params: gan_loss(d_params, g_params, batch, z_key, train=True)[0]\n",
    "        d_grad = jax.grad(compute_d_loss)(d_params)\n",
    "        d_updates, opt_d_state = d_optimizer.update(d_grad, opt_d_state)\n",
    "        d_params = optax.apply_updates(d_params, d_updates)\n",
    "\n",
    "    # Train generator\n",
    "    compute_g_loss = lambda g_params: gan_loss(d_params, g_params, batch, key, train=True)[1]\n",
    "    g_grad = jax.grad(compute_g_loss)(g_params)\n",
    "    g_updates, opt_g_state = g_optimizer.update(g_grad, opt_g_state)\n",
    "    g_params = optax.apply_updates(g_params, g_updates)\n",
    "\n",
    "    return d_params, g_params, opt_d_state, opt_g_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80891322-1050-4d88-8535-537af639b635",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142115e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_params = generator.init(next(prng_seq), jax.random.normal(next(prng_seq), (1, config['latent_dim'])))\n",
    "d_params = discriminator.init(next(prng_seq), X_train[:1, ...], train=False)\n",
    "opt_g_state = g_optimizer.init(g_params)\n",
    "opt_d_state = d_optimizer.init(d_params)\n",
    "bm = BatchManager(X_train, config['batch_size'], key=next(prng_seq))\n",
    "d_train_losses = []\n",
    "g_train_losses = []\n",
    "d_test_losses = []\n",
    "g_test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84703379",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(config['epochs']), \"Epoch\"):\n",
    "    for _ in range(bm.num_batches):\n",
    "        batch = next(bm)\n",
    "        d_params, g_params, opt_d_state, opt_g_state = do_batch_update(\n",
    "            batch, d_params, g_params, opt_d_state, opt_g_state, next(prng_seq))\n",
    "    d_train_loss, g_train_loss = gan_loss(d_params, g_params, X_train, next(prng_seq), train=False)\n",
    "    d_test_loss, g_test_loss = gan_loss(d_params, g_params, X_test, next(prng_seq), train=False)\n",
    "    d_train_losses.append(-d_train_loss)\n",
    "    g_train_losses.append(g_train_loss)\n",
    "    d_test_losses.append(-d_test_loss)\n",
    "    g_test_losses.append(g_test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5be478",
   "metadata": {},
   "source": [
    "## Training Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply moving average filter to losses\n",
    "window_size = 10\n",
    "window = np.ones(window_size) / window_size\n",
    "d_train_losses_f = np.convolve(d_train_losses, window, mode='valid')\n",
    "g_train_losses_f = np.convolve(g_train_losses, window, mode='valid')\n",
    "d_test_losses_f = np.convolve(d_test_losses, window, mode='valid')\n",
    "g_test_losses_f = np.convolve(g_test_losses, window, mode='valid')\n",
    "x_pos = np.arange(window_size // 2, window_size // 2 + d_train_losses_f.shape[0])\n",
    "\n",
    "plt.plot(x_pos, d_train_losses_f, label='D Train')\n",
    "plt.plot(x_pos, g_train_losses_f, label='G Train')\n",
    "plt.plot(x_pos, d_test_losses_f, label='D Test')\n",
    "plt.plot(x_pos, g_test_losses_f, label='G Test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcfe699-3cfa-431a-9d7c-a03362201af5",
   "metadata": {},
   "source": [
    "## Sample Generation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac2217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate samples from the generator\n",
    "def generate_samples(g_params: chex.ArrayTree, key: chex.PRNGKey, num_samples:int):\n",
    "    z = jax.random.normal(key, (num_samples, config['latent_dim']))\n",
    "    samples = generator.apply(g_params, z)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c06451-8ac8-4fbf-ad03-6d361d1054f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "samples = generate_samples(g_params, next(prng_seq), 2000)\n",
    "\n",
    "# Plot samples\n",
    "plt.scatter(samples[:, 0], samples[:, 1], marker='.', label='Sampled')\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], alpha=0.2, marker='o', label='Train')\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], alpha=0.2, marker='o', label='Test')\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.axis('equal')\n",
    "plt.xlim([-4, 4])\n",
    "plt.ylim([-4, 4])\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model outputs\n",
    "save_samples('gan', dataset_name, samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
