{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e94689",
   "metadata": {},
   "source": [
    "# Denoising Score Matching (DSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef9916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import haiku as hk\n",
    "import optax\n",
    "import chex\n",
    "from tqdm import tqdm\n",
    "from utils import BatchManager, load_dataset, save_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3aff95",
   "metadata": {},
   "source": [
    "## Configuration and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8fe9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for each dataset\n",
    "dataset_name = 'checkerboard'\n",
    "dataset_configs = {\n",
    "    'checkerboard': {\n",
    "        'epochs': 5000\n",
    "    },\n",
    "    'gaussian_mixture': {\n",
    "        'epochs': 5000\n",
    "    },\n",
    "    'pinwheel': {\n",
    "        'epochs': 5000\n",
    "    },\n",
    "    'spiral': {\n",
    "        'epochs': 5000\n",
    "    }\n",
    "}\n",
    "\n",
    "config = dataset_configs[dataset_name]\n",
    "config['batch_size'] = 128\n",
    "config['learning_rate'] = 1e-3\n",
    "config['std'] = 0.1\n",
    "config['k'] = 100\n",
    "config['mlp_layer_dim'] = [64, 64, 2]\n",
    "X_train, X_test = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4739db19",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    layer_dim: Sequence[int]\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        for f in self.layer_dim[:-1]:\n",
    "            x = nn.Dense(f)(x)\n",
    "            x = nn.swish(x)\n",
    "        x = nn.Dense(self.layer_dim[-1])(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(layer_dim=config['mlp_layer_dim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e422a69",
   "metadata": {},
   "source": [
    "## Training Preparation\n",
    "Set up the optimizer, loss functions, and other training utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adam(learning_rate=config['learning_rate'])\n",
    "prng_seq = hk.PRNGSequence(jax.random.PRNGKey(0))\n",
    "\n",
    "def dsm_loss(params: chex.ArrayTree, batch: jax.Array, key: chex.PRNGKey, std: float, k: int) -> float:\n",
    "    n, m = batch.shape\n",
    "    batch = jnp.tile(batch[None, :, :], (k, 1, 1))\n",
    "    noise = jax.random.normal(key, batch.shape) * std\n",
    "    noised_batch = noise + batch\n",
    "    fs = model.apply(params, noised_batch.reshape(k * n, m)).reshape(k, n, m)\n",
    "    loss = jnp.sum(jnp.square(noised_batch + std**2 * fs - batch)) / k\n",
    "    return loss\n",
    "\n",
    "@jax.jit\n",
    "def do_batch_update(batch: jax.Array, params: chex.ArrayTree, opt_state: optax.OptState, key: chex.PRNGKey) -> tuple[float, chex.ArrayTree, optax.OptState]:\n",
    "    loss, grad = jax.value_and_grad(dsm_loss)(params, batch, key, std=0.1, k=100)\n",
    "    updates, opt_state = optimizer.update(grad, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return loss, params, opt_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c232f5",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e59fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.init(next(prng_seq), X_train[:1, ...])\n",
    "opt_state = optimizer.init(params)\n",
    "bm = BatchManager(X_train, config['batch_size'], key=next(prng_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ae70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in tqdm(range(config['epochs']), \"Epoch\"):\n",
    "    batch_loss = 0\n",
    "    for _ in range(bm.num_batches):\n",
    "        batch = next(bm)\n",
    "        train_loss, params, opt_state = do_batch_update(batch, params, opt_state, key=next(prng_seq))\n",
    "        batch_loss += train_loss\n",
    "    test_loss = dsm_loss(params, X_test, key=next(prng_seq), std=config['std'], k=config['k'])\n",
    "    train_losses.append(batch_loss / X_train.shape[0])\n",
    "    test_losses.append(test_loss / X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874b8f0",
   "metadata": {},
   "source": [
    "## Training Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8df4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply moving average filer to losses\n",
    "window_size = 100\n",
    "window = np.ones(window_size) / window_size\n",
    "train_losses_f = np.convolve(train_losses, window, mode='valid')\n",
    "test_losses_f = np.convolve(test_losses, window, mode='valid')\n",
    "x_pos = np.arange(window_size // 2, window_size // 2 + train_losses_f.shape[0])\n",
    "\n",
    "plt.plot(train_losses, label='Train Losses')\n",
    "plt.plot(test_losses, label='Test Losses')\n",
    "plt.plot(x_pos, train_losses_f, label='Smoothed Train Losses')\n",
    "plt.plot(x_pos, test_losses_f, label='Smoothed Test Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Denoising Score Matching Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb03df",
   "metadata": {},
   "source": [
    "## Sample Generation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895ce503",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=(\"num_steps\",))\n",
    "def langevin_sampling(params: chex.ArrayTree, key: chex.PRNGKey, step_size: float, initial_samples: jax.Array, num_steps: int) -> jax.Array:\n",
    "    def scan_fn(carry, _):\n",
    "        states, key = carry\n",
    "        key, sk = jax.random.split(key)\n",
    "        noise = jax.random.normal(sk, shape=states.shape)\n",
    "        next_states = states + step_size * model.apply(params, states) + jnp.sqrt(2 * step_size) * noise\n",
    "        return (next_states, key), None\n",
    "\n",
    "    states = initial_samples\n",
    "    (states, _), _ = jax.lax.scan(scan_fn, (states, key), jnp.arange(num_steps))\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c80a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = langevin_sampling(params, next(prng_seq), 5e-3, 2 * jax.random.normal(next(prng_seq), shape=(2000, 2)), 1000)\n",
    "\n",
    "plt.scatter(samples[:, 0], samples[:, 1], marker='.', label='Sampled')\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], alpha=0.2, marker='o', label='Train')\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], alpha=0.2, marker='o', label='Test')\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.axis('equal')\n",
    "plt.xlim([-4, 4])\n",
    "plt.ylim([-4, 4])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9e9e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model outputs\n",
    "save_samples('dsm', dataset_name, samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
