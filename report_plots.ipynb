{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Plots\n",
    "Create training curve and sample plots for reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import load_losses, load_samples, load_dataset, compute_mean_log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['ebm', 'dsm', 'vae', 'gan']\n",
    "datasets = ['checkerboard', 'gaussian_mixture', 'pinwheel', 'spiral']\n",
    "\n",
    "# Load losses and model samples\n",
    "losses = []\n",
    "samples = np.empty((4, 4, 2000, 2))\n",
    "for i, model in enumerate(models):\n",
    "    losses.append([])\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        losses[i].append(load_losses(model, dataset))\n",
    "        samples[i][j] = load_samples(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test datasets\n",
    "X_train = np.empty((4, 2000, 2))\n",
    "X_test = np.empty((4, 500, 2))\n",
    "for i, dataset in enumerate(datasets):\n",
    "    X_train[i], X_test[i] = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['ebm', 'dsm', 'vae', 'gan']\n",
    "datasets = ['checkerboard', 'gaussian_mixture', 'pinwheel', 'spiral']\n",
    "dataset_names = ['Checkerboard', 'Gaussian Mix', 'Pinwheel', 'Spiral']\n",
    "loss_names = ['Energy Function', 'DSM Loss', 'ELBO Loss', 'Loss']\n",
    "linewidths = [1, 1, 1, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(9, 12), constrained_layout=True)\n",
    "fig.set_constrained_layout_pads(hspace=0.1)\n",
    "for i, model in enumerate(models):\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        ax = axes[i][j]\n",
    "\n",
    "        # Assume `losses` is a list of lists of dicts, indexed [model][dataset]\n",
    "        loss = losses[i][j]\n",
    "\n",
    "        if i == 2:\n",
    "            train_losses = loss['train'][2:]\n",
    "            test_losses = loss['test'][2:]\n",
    "        elif i != 3:\n",
    "            train_losses = loss['train']\n",
    "            test_losses = loss['test']\n",
    "\n",
    "        # Plotting train and test losses\n",
    "        if i != 3:\n",
    "            ax.plot(train_losses, label='Train' if j == 0 else \"\", linewidth=linewidths[i])\n",
    "            ax.plot(test_losses, label='Test' if j == 0 else \"\", linewidth=linewidths[i])\n",
    "\n",
    "        if i == 0:\n",
    "            ax.plot(loss['sample'], label='Sample' if j == 0 else \"\", zorder=1, linewidth=linewidths[i])\n",
    "        elif i == 3:\n",
    "            ax.plot(loss['d_train'], label='Discriminator Train' if j == 0 else \"\", linewidth=linewidths[i])\n",
    "            ax.plot(loss['g_train'], label='Generator Train' if j == 0 else \"\", linewidth=linewidths[i])\n",
    "            ax.plot(loss['d_test'], label='Discriminator Test' if j == 0 else \"\", zorder=1, linewidth=linewidths[i])\n",
    "            ax.plot(loss['g_test'], label='Generator Test' if j == 0 else \"\", zorder=1, linewidth=linewidths[i])\n",
    "        \n",
    "        # Setting x-axis labels only for the bottom row plots\n",
    "        if i == len(models) - 1:\n",
    "            ax.set_xlabel('Epochs')\n",
    "        \n",
    "        # Setting y-axis labels only for the first column\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(loss_names[i])\n",
    "\n",
    "        ax.set_title(f'{model.upper()} - {dataset_names[j]}')\n",
    "\n",
    "# Adding individual legends between rows\n",
    "y_offsets = [0.742, 0.492, 0.242, -0.025]\n",
    "for i in range(4):\n",
    "    handles, labels = axes[i, 0].get_legend_handles_labels()\n",
    "    y_offset = y_offsets[i]  # Adjust the vertical offset for each row's legend\n",
    "    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.535, y_offset), ncol=len(labels))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_data(ax, X_train, samples):\n",
    "    ax.scatter(samples[:, 0], samples[:, 1], marker='.', label='Model', s=5)\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], alpha=0.2, marker='o', label='True', s=5)\n",
    "    ax.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(dataset_num1, dataset_num2):\n",
    "    fig, axs = plt.subplots(4, 2, figsize=(8, 12))\n",
    "\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        dataset_num = dataset_num1 if i < 4 else dataset_num2\n",
    "        subplot_data(ax, X_train[dataset_num], samples[i % 4][dataset_num])\n",
    "        ax.set_title(f'{models[i % 4].upper()} - {dataset_names[dataset_num]}')\n",
    "        if i >= 6:\n",
    "            ax.set_xlabel(\"$x_1$\")\n",
    "        if i % 2 == 0:\n",
    "            ax.set_ylabel(\"$x_2$\")\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout(h_pad=0.01)  # Adjust subplots to fit in the figure area.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean log likelihoods:\n",
      "EBM - Checkerboard: -3.9586493960641933\n",
      "DSM - Checkerboard: -4.624172089712637\n",
      "VAE - Checkerboard: -4.1451705599782604\n",
      "GAN - Checkerboard: -5.375529689816331\n",
      "EBM - Gaussian Mix: -54.21946153130514\n",
      "DSM - Gaussian Mix: -1.34391219405919\n",
      "VAE - Gaussian Mix: -7.8567495007881485\n",
      "GAN - Gaussian Mix: -291.28479284440215\n",
      "EBM - Pinwheel: -269.1584507992238\n",
      "DSM - Pinwheel: -3.115764020200447\n",
      "VAE - Pinwheel: 0.43892131380381066\n",
      "GAN - Pinwheel: -10.27649885940689\n",
      "EBM - Spiral: -109.84183995863016\n",
      "DSM - Spiral: -4.410620496426235\n",
      "VAE - Spiral: 0.5177414991079438\n",
      "GAN - Spiral: -2.5325449397882784\n"
     ]
    }
   ],
   "source": [
    "print('Mean log likelihoods:')\n",
    "for j, dataset in enumerate(datasets):\n",
    "    for i, model in enumerate(models):\n",
    "        log_likelihood = compute_mean_log_likelihood(samples[i][j], X_test[i][j])\n",
    "        print(f'{model.upper()} - {dataset_names[j]}:', log_likelihood)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
